from typing import List, Union

from plum import Dispatcher, Function, clear_all_cache

from .util import benchmark


def assert_cache_performance(f, f_native):
    # Time the performance of a native call.
    dur_native = benchmark(f_native, (1,), n=250, burn=10)

    def resolve_registrations():
        for f in Function._instances:
            f._resolver

    def setup_no_cache():
        clear_all_cache()
        resolve_registrations()

    # Time the performance of a cache miss.
    dur_first = benchmark(f, (1,), n=250, burn=10, setup=setup_no_cache)

    # Time the performance of a cache hit.
    clear_all_cache()
    resolve_registrations()
    dur = benchmark(f, (1,), n=250, burn=10)

    assert (
        dur <= 50 * dur_native
    ), "A cached call should not be more than 50 times slower than a native call"

    assert (
        dur_first <= 2000 * dur
    ), "A first call should not be more than 2000 times slower than a cached call"

    assert (
        dur <= dur_first / 4
    ), "The cached call should be at least 4 times faster than a first call"


def test_cache_function():
    dispatch = Dispatcher()

    def f_native(x):
        pass

    @dispatch
    def f(x):
        pass

    @dispatch
    def f(x: Union[int, float]):
        pass

    @dispatch
    def f(x: Union[int, float, str]):
        pass

    # Test performance.
    assert_cache_performance(f, f_native)

    # Test cache correctness.
    assert f(1) is None

    @dispatch
    def f(x: int):
        return 1

    assert f(1) == 1


# This class needs to be in the global scope, otherwise it cannot its methods cannot
# obtains a reference to it.


class A:
    _dispatch = Dispatcher()

    @_dispatch
    def __call__(self, x: int):
        pass

    @_dispatch
    def __call__(self, x: str):
        pass

    @_dispatch
    def go(self, x: int):
        pass

    @_dispatch
    def go(self, x: str):
        pass

    @_dispatch
    def go_again(self, x: int):
        pass

    @_dispatch
    def go_again(self, x: str):
        pass


def test_cache_class():
    class ANative:
        def __call__(self, x):
            pass

        def go(self, x):
            pass

        def go_again(self, x):
            pass

    a_native = ANative()
    a = A()

    # Test performance of calls.
    assert_cache_performance(a, a_native)

    # Test performance of method calls.
    assert_cache_performance(lambda x: a.go(x), lambda x: a_native.go(x))

    # Test performance of static calls.
    assert_cache_performance(
        lambda x: A.go_again(a, x),
        lambda x: ANative.go_again(a_native, x),
    )


def test_cache_clearing():
    dispatch = Dispatcher()

    @dispatch
    def f(x: int):
        return 1

    @dispatch
    def f(x: float):
        return 2

    assert f._methods_registry._resolver is None

    assert f(1) == 1
    # Check that cache is used.
    assert len(f._methods_registry._resolver._cache) == 1
    assert len(f._methods_registry._resolver) == 2

    # Clear via the dispatcher.
    dispatch.clear_cache()
    assert f._methods_registry._resolver is None

    # Run the function again.
    assert f(1) == 1
    assert len(f._methods_registry._resolver._cache) == 1
    assert len(f._methods_registry._resolver) == 2

    # Clear via `clear_all_cache`.
    clear_all_cache()
    assert f._methods_registry._resolver is None

    # Run the function one last time.
    assert f(1) == 1
    assert len(f._methods_registry._resolver._cache) == 1
    assert len(f._methods_registry._resolver) == 2


def test_cache_unfaithful():
    dispatch = Dispatcher()

    @dispatch
    def f(x: int):
        return 1

    @dispatch
    def f(x: List[int]):
        return 2

    # Since `f` is not faithful, no cache should be accumulated.
    assert f(1) == 1
    assert f([1]) == 2
    assert len(f._methods_registry._resolver._cache) == 0
